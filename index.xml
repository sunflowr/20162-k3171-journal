<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>20162-K3171 - Interaction Design: Interactivity: Journal</title>
    <link>https://sunflowr.github.io/20162-k3171-journal/index.xml</link>
    <description>Recent content on 20162-K3171 - Interaction Design: Interactivity: Journal</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Released under the MIT license&lt;br&gt;Powered by [Hugo](//gohugo.io/) with the [Type Theme](//github.com/digitalcraftsman/hugo-type-theme)</copyright>
    <lastBuildDate>Thu, 27 Oct 2016 19:48:52 +0100</lastBuildDate>
    <atom:link href="https://sunflowr.github.io/20162-k3171-journal/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Module4 presentation</title>
      <link>https://sunflowr.github.io/20162-k3171-journal/post/20161027/</link>
      <pubDate>Thu, 27 Oct 2016 19:48:52 +0100</pubDate>
      
      <guid>https://sunflowr.github.io/20162-k3171-journal/post/20161027/</guid>
      <description>

&lt;p&gt;We had decided on meeting up a few minutes earlier to test things out and calibrate sensors and setup Ableton and Max for Live. I was a bit late because I had problem finding the DVI/HDMI adapter for the computer, but we still managed to do the things we planned.&lt;/p&gt;

&lt;p&gt;I think the presentation went fine for most part. I agreed with the feedback that it would have been much better if we had said the text instead of showing it in the video (see Video).&lt;/p&gt;

&lt;p&gt;It also seemed like we failed to convey that we tried lots of different combinations of how we used the sensors before ending up were we currently are.&lt;/p&gt;

&lt;p&gt;We should have been more clear about important finding such as the breaking point were realized best practice (for us in this special case) for using the accelerometer.&lt;/p&gt;

&lt;p&gt;As we didn&amp;rsquo;t get any real critic of the openness, tightness or ambiguity we assume that we applied it in a good way in the interaction.&lt;/p&gt;

&lt;h2 id=&#34;learnings&#34;&gt;Learnings&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Through the sketching process we realized that the best way to use the accelerometer is to stop thinking of it as absolute values and instead use the shifting values over time to to either increase or decrease something.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Another important realisation is that &amp;ldquo;less is more&amp;rdquo; still holds true. After presenting the current sketch to the teachers a few days before the presentation - thinking that we had something that felt good - we quickly realized that the use of so many different sensors and sounds in combination created something very complex and hard to control. The only reason we thought it was &amp;ldquo;ok&amp;rdquo; was because we were so use to it and knew how it worked. After that we tried simplifying the design but removing sounds and simplifying the usage of the accelerometer.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;It&amp;rsquo;s important to setup and explain the limitations (rules) to the person interacting with the artifact - if there&amp;rsquo;s something that could break it. As an example if the person using the chair didn&amp;rsquo;t sit on it with the Y-axis of the accelerometer facing forward when sitting down, the readings would be all wrong.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;demonstrative-video&#34;&gt;Demonstrative video&lt;/h2&gt;

&lt;p&gt;Shows a few examples of the sketch-process as well as the current state of the design.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/xljvnld_xqk&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen frameborder=&#34;0&#34;&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;p&gt;&lt;a href=&#34;https://youtu.be/xljvnld_xqk&#34;&gt;https://youtu.be/xljvnld_xqk&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;links&#34;&gt;Links&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://sunflowr.github.io/20162-k3171-journal/20162-k3171-journal/img/20161026/Interactivity1Project.zip&#34;&gt;Ableton Project&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/xljvnld_xqk&#34;&gt;Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Sketching</title>
      <link>https://sunflowr.github.io/20162-k3171-journal/post/20161021/</link>
      <pubDate>Fri, 21 Oct 2016 21:01:18 +0200</pubDate>
      
      <guid>https://sunflowr.github.io/20162-k3171-journal/post/20161021/</guid>
      <description>

&lt;p&gt;Through most of the day we experimented with applying different effects (volume, panning, filter, delay, reverb, &amp;hellip;) to the sounds and changing different parameters using the X and Y accelerometer sensors and the potentiometer. We discovered that it was hard to noticed if the user was changing the sounds or if the sounds where changing them self. The sounds included very dynamic elements and were already very highly processed with reverb, delays and filters that it was hard to apply anything like this and change the sound subtly.&lt;/p&gt;

&lt;p&gt;It would have been much better if we were allowed to use raw unprocessed waveforms or the sound devices included in Ableton. It would have allowed for more changes. Take a square-wave, we could have mapped sensors to pulse-width and pitch and create lots of changes in the sound without even using filters&lt;/p&gt;

&lt;h3 id=&#34;sketching-z-axis&#34;&gt;Sketching Z-axis&lt;/h3&gt;

&lt;p&gt;I had previously wondered about the third axis - the Z axis - as there were pin-header for connecting it to the Arduino. Today we discovered that actually there were solder holes for soldering in wires to 5V, GND, X,Y and Z. Apparently we had to solder a wire to access the Z-reading.&lt;/p&gt;

&lt;p&gt;It was kind of funny because the Z-axis actually behaved more like we expected a accelerometer to behave. Always striving for a value and when affected with movement jump in the values but as soon as it was still go back towards this middle-value.&lt;/p&gt;

&lt;p&gt;After fixing this we started trying out the Z-axis applying a frequency-shifting effect when force were applied to Z. This turned out to work so satisfyingly well that we held on to that functionality for the rest of the day. The feedback felt so &amp;ldquo;natural&amp;rdquo; and expected in the way the sound went up and down in pitch with the up and down movement of the chair.&lt;/p&gt;

&lt;p&gt;We felt a certain tightness to the interaction and how it behaved, it always seemed to behave the same way and it was easy to understand. But thanks to gravity and precision in motor skills it&amp;rsquo;s hard to feel you have a exact control of it. One of the teaches suggested it made it more ambiguous than tight. As I see tightness as being the about the experienced tightness between the interaction and the feedback from the system and the user understanding the correlation. The more clear this is to the user, the tighter the interaction feels.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;The prevailing buttons in Snoezlen mostly react &lt;em&gt;instantaneously&lt;/em&gt;; that is, cause and effect happen (almost) at the same time, but the buttons separate cause and effect with regards to location and amount of feedback. [&amp;hellip;]&lt;/p&gt;

&lt;p&gt;Attributes of tightness play out differently across the designs. Both &lt;em&gt;MalleablePillow&lt;/em&gt; and &lt;em&gt;ActiveCurtain&lt;/em&gt; give feedback instantaneously where they are touched, and they react proportionally.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(Larsen, 2015)&lt;/p&gt;

&lt;p&gt;Ambiguousness is about a lack of understanding of how something work, causing the user to guess and in best of cases explore to get a better (deeper) understanding of the feedback from the interaction/artifact/system.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;By impelling people to interpret situations for themselves, it encourages them to start grappling conceptually with systems and their contexts, and thus to establish deeper and more personal relations with meanings offered by the system&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(Gaver, Beaver, &amp;amp; Benford, 2003)&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;d argue that the two don&amp;rsquo;t necessarily have to be in odd to each other in this case. The user can experience a direct result of sitting on the chair - tightness:&lt;/p&gt;

&lt;p&gt;Playing of a sound and hearing it change in pitch with the movement.&lt;/p&gt;

&lt;p&gt;But there&amp;rsquo;s still the question if the user instantly realize that moving up and down changes the pitch of the sound or if this is something that will be realized through exploration - ambiguity.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;p&gt;Larsen, H. S. (2015). &lt;em&gt;Tangible participation engaging designs &amp;amp; designerly engagements in pedagogical praxes&lt;/em&gt;. Retrieved from &lt;a href=&#34;http://lup.lub.lu.se/record/5265731&#34;&gt;http://lup.lub.lu.se/record/5265731&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Gaver, W. W., Beaver, J., &amp;amp; Benford, S. (2003). &lt;em&gt;Ambiguity as a resource for design&lt;/em&gt;. . doi:10.&lt;sup&gt;1145&lt;/sup&gt;&amp;frasl;&lt;sub&gt;642611&lt;/sub&gt;.642653&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sensing the chair</title>
      <link>https://sunflowr.github.io/20162-k3171-journal/post/20161020/</link>
      <pubDate>Thu, 20 Oct 2016 20:33:10 +0200</pubDate>
      
      <guid>https://sunflowr.github.io/20162-k3171-journal/post/20161020/</guid>
      <description>

&lt;p&gt;Today we fixed with the chair. The idea was to use a typical office chair unfortunately it turns out it was hard to attach the potentiometer to them. After looking around for different solutions to this and talking to the people in the workshop area we found some chairs that we were able to pull apart easier to attach the potentiometer.&lt;/p&gt;

&lt;p&gt;In order to fix the potentiometer to the chair we pulled it apart and took a wooden block and attached it to the chair and drilled a hole for the potentiometer to sit in (see attached photos).&lt;/p&gt;

&lt;p&gt;We had a few ideas on how to the actual connection between the turning part of the chair and the potentiometer. But most of them required much work to get it working. In the end we realized we could just do it similar to how old belt-driven record players work. So we put a elastic around the rotating part and the potentiometer and rely on friction to turn the knob. It seemed to work really well so we went with this idea.&lt;/p&gt;

&lt;p&gt;We quickly realized it was better to attach the accelerometer to the chair instead of the user. It fixed issues regarding how the user would have been limited in the movement by the wires attached to the accelerometer. In this way it also put the focus all on the chair and allowed for more flowing openness for the users. The user now just had to sit down without first having to attach some device before using the artifact.&lt;/p&gt;

&lt;p&gt;After this we finally felt ready to start sketching.&lt;/p&gt;

&lt;h3 id=&#34;sketching&#34;&gt;Sketching&lt;/h3&gt;

&lt;p&gt;Most of todays sketches was about getting to know the sensors and what we can expect from them and how to use them.&lt;/p&gt;

&lt;p&gt;We played around with X and Y axis mostly as we found them very confusing. We expected them to be continuously changing with the movement (or lack of movement). But instead it seemed to give us something that looked more like absolute values that you would expect from a gyroscope. We did lots of tests and felt that this behaviour seemed to happen each time so we decided on using it in this more &amp;ldquo;gyroscopic&amp;rdquo; way, using the values to measure how far the user were leaning in a direction.&lt;/p&gt;

&lt;h3 id=&#34;photos&#34;&gt;Photos&lt;/h3&gt;

&lt;p&gt;Chair full view&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://sunflowr.github.io/20162-k3171-journal/20162-k3171-journal/img/20161020/chair_full.jpg&#34; alt=&#34;Chair full view&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Chair detailed view of potentiometer&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://sunflowr.github.io/20162-k3171-journal/20162-k3171-journal/img/20161020/chair_detail.jpg&#34; alt=&#34;Chair detailed view&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Chair full view of all sensors&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://sunflowr.github.io/20162-k3171-journal/20162-k3171-journal/img/20161020/chair_sensor.jpg&#34; alt=&#34;Chair sensors&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Chair detailed view of all the sensors&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://sunflowr.github.io/20162-k3171-journal/20162-k3171-journal/img/20161020/chair_sensor_detail.jpg&#34; alt=&#34;Chair sensors detailed&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Thursday</title>
      <link>https://sunflowr.github.io/20162-k3171-journal/post/20161019/</link>
      <pubDate>Wed, 19 Oct 2016 20:44:07 +0200</pubDate>
      
      <guid>https://sunflowr.github.io/20162-k3171-journal/post/20161019/</guid>
      <description>&lt;p&gt;This day I unfortunately had to work from home so only had contact with the other group member through chat. We decided on trying out things on our own and see what we could find.&lt;/p&gt;

&lt;p&gt;As I went and bought the accelerometer the day before I thought I try it out today and see how it behaves. I connected it up to the Arduino and tried it out in Max for Live, connecting it to a few parameters and tried moving it around. It seemed to work fine and it looked like we could work with the values.&lt;/p&gt;

&lt;p&gt;Thought it felt clear that it was important to try it with the correct chair as soon as possible as the way I move it with my hand is much different from the movement you make when re-positioning and leaning on a chair.&lt;/p&gt;

&lt;p&gt;Accelerometer sensor used:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://sunflowr.github.io/20162-k3171-journal/20162-k3171-journal/img/20161019/accelerometer.jpg&#34; alt=&#34;Accelerometer sensor&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Module4 introduction</title>
      <link>https://sunflowr.github.io/20162-k3171-journal/post/20161018/</link>
      <pubDate>Tue, 18 Oct 2016 22:21:09 +0200</pubDate>
      
      <guid>https://sunflowr.github.io/20162-k3171-journal/post/20161018/</guid>
      <description>

&lt;p&gt;Today we were presented with &lt;em&gt;Module 4&lt;/em&gt; - the last module for the course. The topic for the module is &lt;em&gt;Body and Sound&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Keywords for the modules are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Tightness - The user can see a direct corelation between its interaction and the feedback from the artifact.&lt;/li&gt;
&lt;li&gt;Ambiguity - Some form of uncertainty in the inner workings, making the artifact feel more alive.&lt;/li&gt;
&lt;li&gt;Openness - There&amp;rsquo;s no fixed state of the interaction, no start/stop condition. It&amp;rsquo;s always sensing the environment and reacting to it. Much like how we humans and most - if not all - living beings.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Material for the module consist of:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Ableton Live with Max for Live&lt;/li&gt;
&lt;li&gt;Arduino using Firmata sketch&lt;/li&gt;
&lt;li&gt;Max two analog sensors&lt;/li&gt;
&lt;li&gt;A few pre-selected audio files.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;idea-generation&#34;&gt;Idea-generation&lt;/h2&gt;

&lt;p&gt;Instructions:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Ideate -&amp;gt; Pick two (sets of) everyday movements.&lt;/li&gt;
&lt;li&gt;Explore the characteristics of these two (sets of) movements with your body.&lt;/li&gt;
&lt;li&gt;Choose one set of movements - work with it, identifying 3-5 of the movements characteristics.&lt;/li&gt;
&lt;li&gt;Make brief description of each of these characteristics.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;movements&#34;&gt;Movements&lt;/h3&gt;

&lt;p&gt;Movements in bold was the once we expanded on.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Shaking hands&lt;/li&gt;
&lt;li&gt;Opening doors&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Drinking coffee&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Smoking&lt;/li&gt;
&lt;li&gt;Read/write&lt;/li&gt;
&lt;li&gt;Flipping pages&lt;/li&gt;
&lt;li&gt;Put on / taking off shoes&lt;/li&gt;
&lt;li&gt;Pick up thing from the floor&lt;/li&gt;
&lt;li&gt;Hugging (man-hug - the awkwardness)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sitting in a office-chair&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Arm-wrestling&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;drinking-coffee&#34;&gt;Drinking coffee&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Holding (the cup)&lt;/li&gt;
&lt;li&gt;Grabbing&lt;/li&gt;
&lt;li&gt;Lifting&lt;/li&gt;
&lt;li&gt;Tilting&lt;/li&gt;
&lt;li&gt;Rotating&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We thought these were some interesting interactions that we could apply sensors to feel, but after talking to a few other groups it felt like everyone was going to do something similar. So we decided on our other options - sitting in a office chair.&lt;/p&gt;

&lt;h4 id=&#34;sitting-in-a-office-chair&#34;&gt;Sitting in a office-chair&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Spinning (the chair)&lt;/li&gt;
&lt;li&gt;Leaning left/right/back/forward&lt;/li&gt;
&lt;li&gt;Sitting down&lt;/li&gt;
&lt;li&gt;Standing up&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We thought this could be an fun thing were we can play around with how people sit in the chair, like how we all re-position our self from time to time without really thinking about it. We&amp;rsquo;re thinking that we could make the person aware with the way the they use the chair. By sensing how the person lean the chair or position it we could either create a feelings such as power or discomfort by playing with the sounds.&lt;/p&gt;

&lt;h2 id=&#34;tech&#34;&gt;Tech&lt;/h2&gt;

&lt;p&gt;We decided we want to put a sensors for sensing the rotation of the chair as the person using it re-position them self and the chair. We think the most viable solution for this is to stick a potentiometer on the chair and connect it between the two rotating parts of the chair. To stop the potentiometer from breaking if the user would do a 360 turn we&amp;rsquo;ve removed the mechanical part in the potentiometer that stops it from rotating a full turn.&lt;/p&gt;

&lt;p&gt;We also decided on using a accelerometer from TinkerKit as the one provided by the teacher communicate using I2C. The accelerometer provide sensors for the X, Y and Z axis. The idea is to be able to sense the bodily movement of the person using the chair.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://sunflowr.github.io/20162-k3171-journal/20162-k3171-journal/img/20161018/chair_sensors.jpg&#34; alt=&#34;Chair sensors&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;links&#34;&gt;Links&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.electrokit.com/tinkerkit-accelerometer-2-3-riktningar.51862&#34;&gt;TinkerKit Accelerometer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Module3 presentation</title>
      <link>https://sunflowr.github.io/20162-k3171-journal/post/20161013/</link>
      <pubDate>Thu, 13 Oct 2016 19:23:19 +0200</pubDate>
      
      <guid>https://sunflowr.github.io/20162-k3171-journal/post/20161013/</guid>
      <description>

&lt;p&gt;For the presentation we presented how we came to the current design; going from from the initial ideas to how we combined them picking out the essence of what we tried doing - allow the user to move faster through a article based system, something we call &lt;em&gt;fast scroll&lt;/em&gt; or &lt;em&gt;filter scroll&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;We also talked a bit about how we wanted to incorporate force touch to allow for either interacting with comments within the article or as a way to allow for the activation of the functionality any where on the screen rather than having it region-based.&lt;/p&gt;

&lt;h2 id=&#34;presentation&#34;&gt;Presentation&lt;/h2&gt;

&lt;p&gt;The main critic would probably be around if this would have worked with out the very clearly painted touch regions we used in the presentation. This is something that we should have tested to see if it would have caused confusions.&lt;/p&gt;

&lt;p&gt;It could also be argued on how we interpreted &lt;em&gt;nuance&lt;/em&gt;, while we certainly allowed for a nuance in they way the person scrolls between texts, it&amp;rsquo;s not a gradual smooth way. It&amp;rsquo;s more of a step-based approach.&lt;/p&gt;

&lt;p&gt;It would also have been good to test this out in landscape view and evaluate if this is interaction that works in any mode or if the width of the screen makes any difference to the interaction.&lt;/p&gt;

&lt;h2 id=&#34;links&#34;&gt;Links&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/sunflowr/20162-k3171-module3&#34;&gt;GitHub project&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/stuyam/pressure/&#34;&gt;Pressure.js&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Presentation preparations</title>
      <link>https://sunflowr.github.io/20162-k3171-journal/post/20161012/</link>
      <pubDate>Wed, 12 Oct 2016 20:50:12 +0200</pubDate>
      
      <guid>https://sunflowr.github.io/20162-k3171-journal/post/20161012/</guid>
      <description>&lt;p&gt;Prepare presentation&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Monday</title>
      <link>https://sunflowr.github.io/20162-k3171-journal/post/20161010/</link>
      <pubDate>Mon, 10 Oct 2016 21:52:03 +0200</pubDate>
      
      <guid>https://sunflowr.github.io/20162-k3171-journal/post/20161010/</guid>
      <description>&lt;p&gt;Sick, working from home.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Almost there</title>
      <link>https://sunflowr.github.io/20162-k3171-journal/post/20161009/</link>
      <pubDate>Sun, 09 Oct 2016 22:05:43 +0200</pubDate>
      
      <guid>https://sunflowr.github.io/20162-k3171-journal/post/20161009/</guid>
      <description>&lt;p&gt;Got the filtering and scrolling working properly.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Most stuff working</title>
      <link>https://sunflowr.github.io/20162-k3171-journal/post/20161007/</link>
      <pubDate>Fri, 07 Oct 2016 20:40:23 +0100</pubDate>
      
      <guid>https://sunflowr.github.io/20162-k3171-journal/post/20161007/</guid>
      <description>&lt;p&gt;Worked more on prototype, got most of the things working today. Had some issues with scrolling to certain post and how to solve it.&lt;/p&gt;

&lt;p&gt;Wondered&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Idea generation</title>
      <link>https://sunflowr.github.io/20162-k3171-journal/post/20161005/</link>
      <pubDate>Wed, 05 Oct 2016 19:34:36 +0200</pubDate>
      
      <guid>https://sunflowr.github.io/20162-k3171-journal/post/20161005/</guid>
      <description>

&lt;h3 id=&#34;ideas&#34;&gt;Ideas&lt;/h3&gt;

&lt;h4 id=&#34;limitations&#34;&gt;Limitations&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Platform - mobile phone&lt;/li&gt;
&lt;li&gt;Use touch gesture&lt;/li&gt;
&lt;li&gt;Use pixels as indicator&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;force-touch-hold-to-call-favorite&#34;&gt;Force-touch - hold to call favorite&lt;/h4&gt;

&lt;p&gt;When user force touch over a certain threshold on the Phone icon the user is given the option to call a favorite contact without having to go through the contact book.&lt;/p&gt;

&lt;h4 id=&#34;multi-touch-swipe-skip-x-pages&#34;&gt;Multi-touch swipe - skip X pages&lt;/h4&gt;

&lt;p&gt;Depending on amount of fingers touching the screen when swiping skip X amount of pages. E.g. when flicking through the app pages, instead of swiping three times to go from page 1 to page 3, swipe with two fingers to jump forward two pages instead.&lt;/p&gt;

&lt;h4 id=&#34;swipe-gesture-on-the-home-button&#34;&gt;Swipe gesture on the &amp;ldquo;Home button&amp;rdquo;&lt;/h4&gt;

&lt;p&gt;Considering that the &amp;ldquo;home button&amp;rdquo; now day seem to be smarter than just a regular button (e.g. finger recognition) we wondered if it would be possible to some how detect gestures on it.&lt;/p&gt;

&lt;p&gt;How could interacting using gestures on this button rather than the screen aid in everyday actions on the phone?&lt;/p&gt;

&lt;h4 id=&#34;interactive-billboards&#34;&gt;Interactive billboards&lt;/h4&gt;

&lt;p&gt;What would happen if public billboards were more like gigantic interactive screens?&lt;/p&gt;

&lt;p&gt;How would it handle multiple users?&lt;/p&gt;

&lt;p&gt;Would it make people take more notice to and engage more in the message on the billboard (e.g. even if it were a commercial for toothbrushes).&lt;/p&gt;

&lt;h4 id=&#34;pinching-for-overview&#34;&gt;Pinching for overview&lt;/h4&gt;

&lt;p&gt;Similar to how it&amp;rsquo;s used on OSX give the user a overview screen of all the active applications; doing this on the phone could as an example present the available pages on the home screen of the phone for faster movement.&lt;/p&gt;

&lt;h4 id=&#34;misc-ideas&#34;&gt;Misc ideas&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Is there any reason for not interacting using the foot more?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;selected-idea-fast-scroll-filter-scroll&#34;&gt;Selected idea - Fast scroll / filter scroll.&lt;/h3&gt;

&lt;p&gt;After a bit more discussions and consulting with the teacher we ended up with a combination of some ideas that we evolved into our current idea.
We aim to create something that could be used in context of social media, news site and other sites that are based on articles/posts.&lt;/p&gt;

&lt;p&gt;The idea is to allow the user to do fast scroll / filter scroll to quickly skip articles in the article feed based on some search criteria.&lt;/p&gt;

&lt;p&gt;In order to do this we split the screen into multiple areas. One area functions like normal and allow the user to scroll normally, the other area(s) act as zones that react on swipe up/down and react by searching for next/previous post using the selected search criteria.&lt;/p&gt;

&lt;p&gt;The idea is to allow the user to for example skip posts in social media to jump to next post for a certain friend, page or group without having to scroll forever.&lt;/p&gt;

&lt;p&gt;We also have some extra ideas with using force-touch to scroll within post comments that we&amp;rsquo;re considering trying.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://sunflowr.github.io/20162-k3171-journal/20162-k3171-journal/img/20161005/sketch.jpg&#34; alt=&#34;sketch&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Module3 introduction</title>
      <link>https://sunflowr.github.io/20162-k3171-journal/post/20161003/</link>
      <pubDate>Mon, 03 Oct 2016 22:18:10 +0200</pubDate>
      
      <guid>https://sunflowr.github.io/20162-k3171-journal/post/20161003/</guid>
      <description>

&lt;p&gt;Today module 3 was presented to us. The keyword is &amp;lsquo;Nuance&amp;rsquo; and as far as I interpreted it, it&amp;rsquo;s abut expressiveness and flow in the interaction. To simplify step based interactions into something much more fluid and natural feeling.&lt;/p&gt;

&lt;p&gt;Material / requirements for the module is touch and pixels. Target device can be anything phone, tablet, billboard, printer, something that don&amp;rsquo;t exist yet.&lt;/p&gt;

&lt;h3 id=&#34;lecture&#34;&gt;Lecture&lt;/h3&gt;

&lt;h4 id=&#34;skillful-coping&#34;&gt;Skillful coping&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;To keep up with a situation.&lt;/li&gt;
&lt;li&gt;Things seem to &amp;ldquo;fall into place&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;We do just the right thing at the right moment.&lt;/li&gt;
&lt;li&gt;Seem to flow, don&amp;rsquo;t need to know about the how.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;ideas&#34;&gt;Ideas&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Start with something with limited nuance.&lt;/li&gt;
&lt;li&gt;Look for interactions that involve repeated steps, or selection from a menu menu option.&lt;/li&gt;
&lt;li&gt;See if you can &amp;ldquo;collapse&amp;rdquo; it down into a single expressive action.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;material-quality&#34;&gt;Material quality&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Maybe pixels can be used and feed-forward in a abstract non-symbolic way?&lt;/li&gt;
&lt;li&gt;How could touch be used more for continuous fluid interaction rather than poking fake buttons?&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;user-stories&#34;&gt;User stories&lt;/h4&gt;

&lt;p&gt;Example 1&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;MAH printer system requires multiple steps in order to print, even in the case where the user want&amp;rsquo;s to print everything, or the there&amp;rsquo;s only one thing in the queue. It would be desirable if the user could in a easy manner skip this friction in the interaction and create a flow, making the experience better and give the user more expressiveness in it&amp;rsquo;s way of commanding the printer.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;notes&#34;&gt;Notes&lt;/h4&gt;

&lt;p&gt;Kattegat contains a good collection of touch related samples.&lt;/p&gt;

&lt;h5 id=&#34;kattegat&#34;&gt;Kattegat&lt;/h5&gt;

&lt;p&gt;Install:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;$ npm install -g generator-kattegat&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Create project:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;$ yo kattegat&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Start:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;$ npm start [tunnel]&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;links&#34;&gt;Links&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://developer.telerik.com/featured/a-concise-guide-to-remote-debugging-on-ios-android-and-windows-phone/&#34;&gt;Setting up remote debugging on phone&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Presentation of Module2</title>
      <link>https://sunflowr.github.io/20162-k3171-journal/post/20160929/</link>
      <pubDate>Fri, 30 Sep 2016 19:08:02 +0200</pubDate>
      
      <guid>https://sunflowr.github.io/20162-k3171-journal/post/20160929/</guid>
      <description>

&lt;p&gt;We meet up in the morning to test so everything worked, of course it didn&amp;rsquo;t.
One important wire was broken and needed replacement and one vibrator wire needed to be re-attached.&lt;/p&gt;

&lt;p&gt;After we confirmed everything as working we went to the presentation.&lt;/p&gt;

&lt;h3 id=&#34;presentation&#34;&gt;Presentation&lt;/h3&gt;

&lt;p&gt;While a bit nervous the presentation went fine. They seemed to think it was an interesting concept. Nothing really negative to say about it. They suggested taking a step back from our context and see in what other areas/context the idea could be used - to explore outside the context.&lt;/p&gt;

&lt;p&gt;They seemed to like the idea of giving one of the user all the control (touch) while the other loosing the control (user with vibrator) having to rely on the other user.&lt;/p&gt;

&lt;h3 id=&#34;end-result&#34;&gt;End result&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://sunflowr.github.io/20162-k3171-journal/20162-k3171-journal/img/20160929/sensor.jpg&#34; alt=&#34;sensor clothing&#34; /&gt;
&lt;img src=&#34;https://sunflowr.github.io/20162-k3171-journal/20162-k3171-journal/img/20160929/vibrator.jpg&#34; alt=&#34;vibrator clothing&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/sunflowr/school-stuff-20162-k3171---module2/&#34;&gt;github code&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>2016-09-28: Status update</title>
      <link>https://sunflowr.github.io/20162-k3171-journal/post/20160928/</link>
      <pubDate>Wed, 28 Sep 2016 16:48:07 +0200</pubDate>
      
      <guid>https://sunflowr.github.io/20162-k3171-journal/post/20160928/</guid>
      <description>

&lt;p&gt;Today we&amp;rsquo;ve worked some more on the prototype.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;We attached the sensors and vibrators to the two cloth-pieces. (see attached image)&lt;/li&gt;
&lt;li&gt;Added communication code using the &lt;a href=&#34;https://www.arduino.cc/en/Reference/Wire&#34;&gt;Wire Library&lt;/a&gt; for communication between the two Arduino devices.&lt;/li&gt;
&lt;li&gt;Fixed battery adaptors for the Arduinos.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://sunflowr.github.io/20162-k3171-journal/20162-k3171-journal/img/20160928/svsketch.jpg&#34; alt=&#34;sensor and vibrator sketch&#34; /&gt;
&lt;img src=&#34;https://sunflowr.github.io/20162-k3171-journal/20162-k3171-journal/img/20160928/vclothing.jpg&#34; alt=&#34;vibrator clothing&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;notes&#34;&gt;Notes&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Social akwardness&lt;/li&gt;
&lt;li&gt;Positive/negative feelings subjective - e.g. rollercoaster&amp;rsquo;s amount of scary-fun depends on the user.&lt;/li&gt;
&lt;li&gt;Self sacrifice&lt;/li&gt;
&lt;li&gt;Control frame - give user more control (more control good/bad? more control of other good/bad?)&lt;/li&gt;
&lt;li&gt;Positive: Breaking ice&lt;/li&gt;
&lt;li&gt;Negative: Making yourself center of attention / making fool of yoursef.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;issues&#34;&gt;Issues:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Having on Arduino power both of the devices seemed to draw too much current so we decided on using batteries for each device - this should hopefully fix the issue as it&amp;rsquo;s been tested before that one Arduino indeed can power all five vibrators.&lt;/li&gt;
&lt;li&gt;We&amp;rsquo;ve been having issues with the lab wires send with the Arduinos - they seem to either be broken from beginning or breaking too easy. We&amp;rsquo;ve had to replace a few.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;resolved&#34;&gt;Resolved:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;It seems the touch will be fine siting on the clothes as far as we&amp;rsquo;ve tested. No false positives.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Most stuff working</title>
      <link>https://sunflowr.github.io/20162-k3171-journal/post/20160927/</link>
      <pubDate>Tue, 27 Sep 2016 22:01:58 +0200</pubDate>
      
      <guid>https://sunflowr.github.io/20162-k3171-journal/post/20160927/</guid>
      <description>

&lt;p&gt;Got some stuff done today:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Build the vibrator and touch circuits (see attached images)&lt;/li&gt;
&lt;li&gt;Made the cloth-pieces (see attached images)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://sunflowr.github.io/20162-k3171-journal/20162-k3171-journal/img/20160927/vibc.jpg&#34; alt=&#34;Vibrator circuits&#34; /&gt;
&lt;img src=&#34;https://sunflowr.github.io/20162-k3171-journal/20162-k3171-journal/img/20160927/touchc.jpg&#34; alt=&#34;Touch Circuit&#34; /&gt;
&lt;img src=&#34;https://sunflowr.github.io/20162-k3171-journal/20162-k3171-journal/img/20160927/clothing.jpg&#34; alt=&#34;Cloth pieces&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;issues-thoughts&#34;&gt;Issues / thoughts:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Will there be any issue with false positives on the touch if the clothes are sitting too close to the skin of the user? Need to be tested!&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;resolved&#34;&gt;Resolved:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;The Arduino seem to be able to power all five vibrators without any problem.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>